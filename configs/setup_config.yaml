assistant_llm:
  # put the unique_model_id that you specified in llm_config.yaml
  prompt_opt: az_gpt_4
dir_info:
  # Base directory in which every generated file would be saved.
  base_dir: /home/user/VeLLMPlatform
  # Directory inside which system log files should be saved
  log_dir_name: glue_logs
experiment_name: gsm8k_redteam
# Many features are different for mode: online/offline. For eg
# 1) Print of logs happens on console for offline mode
# 2) LLM Queue gets instantiated only in online mode
mode: offline
# Full length description of the experiment. This would be logged.
description:
# content_moderation is optional. If you don't want to specify content_moderation,
# remove this entire field & its sub-fields.
content_moderation:
  # If set to true, then content_moderation would be enabled.
  enable_moderation: true
  # If content_severity crosses this threshold then the processing would be blocked
  content_severity_threshold: 2
  # If jailbreak detection is required. 
  jailbreak_detection: true
  # Additional guidelines to constrain any malicious behavior
  include_metaprompt_guidelines: true
  # Azure AI Content Safety (AACS) Endpoint
  aacs:
    subscription_id: "**"
    resource_group: "**"
    name: "resource_name"
    location: "east us"
    sku_name: "S0"
    use_azure_ad: true
    ## Specify the authentication method to be used for AACS
    ## if use_azure_ad is set to True, then use the following resource will be accessed using Azure AD
    ## else the resource will be accessed using Key based authentication, key is automatically fetched. No need to pass the key.